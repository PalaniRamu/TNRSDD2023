# -*- coding: utf-8 -*-
"""TNRSDD2023_Detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1slVZZzFEIM_IO-rcaC6CfMF-qi_ilUhM

# How to Train YOLOv7 on a Custom Dataset

This tutorial is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. This notebook shows training on **your own custom objects**. Many thanks to WongKinYiu and AlexeyAB for putting this repository together.

### **Steps Covered in this Tutorial**

To train our detector we take the following steps:

* Install YOLOv7 dependencies
* Evaluate YOLOv7 performance
* OPTIONAL: Deployment
* OPTIONAL: Active Learning


### Preparing a Custom Dataset

In this tutorial, we will utilize an open source computer vision dataset from one of the 90,000+ available on [Roboflow Universe](https://universe.roboflow.com).

If you already have your own images (and, optionally, annotations), you can convert your dataset using [Roboflow](https://roboflow.com), a set of tools developers use to build better computer vision models quickly and accurately. 100k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to YOLOv7), training, deploying, and improving their datasets/models.

Follow [the getting started guide here](https://docs.roboflow.com/quick-start) to create and prepare your own custom dataset.

## Custom Dataset preparation using Distinct image frmes
"""

# step 1 : Library initialisation & folder creation
# Below library included 
import os
import cv2 as cv
from time import time
from skimage.metrics import structural_similarity
import shutil
import glob

# common variable alue assigned here
Projpath='/content/RSDD2022'
Videofilepath='/content/RSDD2022/Video'
Outputpath='/content/RSDD2022/Output/'
Uniqueframepath='/content/RSDD2022/Uniqueframes'

def structure_create():
  if not os.path.isdir(Projpath):
    os.mkdir(Projpath) # project folder name
  if not os.path.isdir(Videofilepath):
    os.mkdir(Videofilepath)  # load video file to be convert to frames
  if not os.path.isdir(Uniqueframepath):
    os.mkdir(Uniqueframepath) # Distinct frames are in this folder
  if not os.path.isdir(Outputpath):
    os.mkdir(Outputpath) # the converted frames are in this folder

structure_create()
print("Directory structure created" )

'''
Step 2: Load Video File by manual
'''

""" 
step 3:  converted video file into image frame with custom names 
"""
Videofilename='/content/RSDD2022/Video/testvideo_3.mp4'

def switch(cnt):
  s=''
  if cnt==0 :
   s= "00000"
  elif cnt <10 and cnt>0:
   s= "0000"+str(cnt)
  elif cnt <100 and cnt>9:
    s="000"+str(cnt)
  elif cnt <1000 and cnt>99:
    s="00"+str(cnt)
  elif cnt <10000 and cnt>990:
    s="0"+str(cnt)
  else :
     s=str(cnt)
  return s 

file = Videofilename
outpath = Outputpath
os.chdir(Videofilepath)
targetpath = Outputpath

shutil.rmtree('/content/RSDD2022/Output')

if not os.path.exists(outpath):
  os.mkdir(outpath)

cap = cv.VideoCapture(file)
total_frame = int(cap.get(cv.CAP_PROP_FRAME_COUNT))

# save the frame on every given seconds
seconds = 0.5
fps = cap.get(cv.CAP_PROP_FPS) # Gets the frames per second
# calculates number of frames that creates 10 seconds of video
multiplier = fps * seconds

# Check if camera opened successfully
if (cap.isOpened()== False):
  print("Error opening video stream or file")
frame_counter = 1
wframe=1
while frame_counter <= total_frame:
  cap.set(cv.CAP_PROP_POS_FRAMES, frame_counter)
  ret, frame = cap.read()
  #print('Ret {}'.format(ret) )
  if ret:
    # save frame  # file path
    file_path = targetpath+'frame_'+ switch(wframe) + ".jpg"
    cv.imwrite(file_path, frame)
  frame_counter += multiplier
  wframe += 1
cap.release()
cv.destroyAllWindows()

""" 
step 4:  Distinct images copied into folder uniqueframes
"""
import os
import cv2 as cv
from time import time
from skimage.metrics import structural_similarity
import shutil
import glob

sourcepath=Outputpath
targetpath=Uniqueframepath

shutil.rmtree('/content/RSDD2022/Uniqueframes')

if not os.path.exists(targetpath):
  os.mkdir(targetpath)

# Get list of all files including sub-directory also.
list_of_files = sorted( filter( os.path.isfile,
                        glob.glob(sourcepath + '/**/*', recursive=True) ) )
i=0
flag=True
while i <= len(list_of_files)-2 :
  im1=list_of_files[i]
  im1=im1.split('/')
  im2=list_of_files[i+1]
  im2=im2.split('/')
  #print("images compared : {} vs {}".format(im1[-1],im2[-1]))
  image1 = cv.imread(list_of_files[i], 0)
  image2 = cv.imread(list_of_files[i+1],0)
# Compute SSIM between the two images
  if image1.shape == image2.shape :
    (score, diff) = structural_similarity(image1, image2, full=True)
    #print( ' sore value{} '.format(score))
    if (score*100) < 60:
      try:
        shutil.copy(list_of_files[i], targetpath)
        shutil.copy(list_of_files[i+1], targetpath)
        i += 1
      # If source and destination are same
      except shutil.SameFileError:
        shutil.copy(list_of_files[i+1], targetpath)
        print("Source and destination represents the same file.")
  i += 1

#step 5: information about process
"""
Summary information of Distinct frame process
"""
cap = cv.VideoCapture(Videofilename)
fps = cap.get(cv.CAP_PROP_FPS)   
frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))
duration = frame_count/fps

print('fps = ' + str(fps))
print('number of frames = ' + str(frame_count))
print('duration (S) = ' + str(duration))
minutes = int(duration/60)
seconds = duration%60
print('duration (M:S) = ' + str(minutes) + ':' + str(seconds))
cap.release()

total_frames = sorted( filter( os.path.isfile,
                        glob.glob(Outputpath + '/**/*', recursive=True) ) )
unique_frames = sorted( filter( os.path.isfile,
                        glob.glob(Uniqueframepath + '/**/*', recursive=True) ) )
print('Total number of converted Image frames: ',len(total_frames))
print('Total number of distinct Image frames : ',len(unique_frames))

"""#Install Dependencies -  Ibrary of Ylov7 

_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_
"""

# Commented out IPython magic to ensure Python compatibility.
# Download YOLOv7 repository and install requirements
!git clone https://github.com/WongKinYiu/yolov7
# %cd /content/yolov7
!pip install -r requirements.txt
!pip install wandb
!pip install torchvision==0.11.3+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html
import torch
from IPython.display import Image, clear_output  # to display images
#from utils.google_utils import gdrive_download  # to download models/datasets
!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt 
clear_output()
print('Setup completed')

# # Commented out IPython magic to ensure Python compatibility.
# from google.colab import drive
# # %cd /content/RSDD2022
# drive.mount('/content/drive')
# #!cp -av "/content/drive/MyDrive/DEVRDD/GRSDD2022/data.yaml" -d "/content/yolov7/"
# #!unzip -u "/content/drive/MyDrive/DEVRDD/GRSDD2022/Datasources/AdditionalSource.zip" -d "/content/RSDD2022/dataset/"
# !unzip -u "/content/drive/MyDrive/DEVRDD/Dump/INRSDD2023.zip" -d "/content/yolov7/dataset/"

# drive.flush_and_unmount()
# clear_output()

''' Augmendation Techniques'''

# Importing necessary functions
from keras.preprocessing.image import ImageDataGenerator,
array_to_img, img_to_array, load_img

# Initialising the ImageDataGenerator class.
# We will pass in the augmentation parameters in the constructor.
datagen = ImageDataGenerator(
		rotation_range = 40,
		shear_range = 0.2,
		zoom_range = 0.2,
		horizontal_flip = True,
		brightness_range = (0.5, 1.5))
	
# Loading a sample image
img = load_img('image.jpg')
# Converting the input sample image to an array
x = img_to_array(img)
# Reshaping the input image
x = x.reshape((1, ) + x.shape)

# Generating and saving 5 augmented samples
# using the above defined parameters.
i = 0
for batch in datagen.flow(x, batch_size = 1,
						save_to_dir ='preview',
						save_prefix ='image', save_format ='jpeg'):
	i += 1
	if i > 5:
		break



#  dataset"""
# ## Split the Data's 80, 20  -- Training
# """
# # Commented out IPython magic to ensure Python compatibility.
# import os,glob
# %cd /content/yolov7/dataset
# #!mkdir
# !mkdir train
# !mkdir test
# !mkdir train/images
# !mkdir train/labels
# !mkdir test/images
# !mkdir test/labels

# base_path = '/content/yolov7/dataset'

# No_of_files = len(glob.glob(base_path+'/*.txt'))

# # print('total Number of files :',No_of_files)
# # print('80% percent :',round((No_of_files/100)*97))
# # print('20% percent :',round((No_of_files/100)*3))

# part1=round((No_of_files/100)*90)
# part2=round((No_of_files/100)*10)

# fcntr=1
# file_list = [filename for filename in glob.glob(base_path+'/*.txt')]
# for file in file_list:
#   if len(glob.glob(file.replace('.txt','*'))) <2 :
#     print ('Jpeg file not found',file)
#     break
#   if fcntr<= part1 :   #  80% files copied in Train files
#     try:
#       #shutil.copyfile( file, '/content/RSDD2022/dataset/train/labels')
#       os.system('cp '+file+ ' /content/yolov7/dataset/train/labels/')
#       file=file.replace('.txt','.jpg')
#       #shutil.copyfile( file, '/content/RSDD2022/dataset/train/images' )
#       os.system('cp '+file+ ' /content/yolov7/dataset/train/images/')
#     except IOError:
#       print('file not found')
#   else:
#     try:
#       os.system('cp '+file+ ' /conten/yolov7/dataset/test/labels/')
#       file=file.replace('.txt','.jpg')
#       os.system('cp '+file+ ' /content/yolov7/dataset/test/images/')
#     except IOError:
#       print('file not found  ' + file)
#   fcntr=fcntr+1

# print('Total No. of Train Image: ',len(glob.glob('/content/yolov7/dataset/train/images/*.jpg')))
# print('Total No. of Test Image: ',len(glob.glob('/content/yolov7/dataset/test/images/*.jpg')))

import shutil,glob
shutil.rmtree('/content/yolov7/dataset/test')
shutil.rmtree('/content/yolov7/dataset/train')
# #shutil.rmtree('/content/RSDD2022/dataset/Data')
# shutil.rmtree('/content/RSDD2022/runs')

# """## Model Training -- Training"""

# # Commented out IPython magic to ensure Python compatibility.
# import collections
# import os
# import glob
# import matplotlib.pyplot as plt
# import matplotlib as matplot
# import seaborn as sns


# base_path = '/content/yolov7/dataset'
# damageTypes=['D00','D10','D20','D40']

# # govs corresponds to municipality name.
# #govs = ['Sunny', 'Raining', 'Winter', 'Darkness']

# # the number of each class labels.
# #count_dict = collections.Counter(cls_names)
# cls_count = []
# total_images=0
# cl01=cl02=cl03=cl04=0
# file_list = [filename for filename in glob.glob(base_path+'/*.txt')]
# for file in file_list:
#   total_images = total_images + 1
#   f = open(file,'r')
#   data = f.read()
#   cl01= cl01+data.count("0 ")
#   cl02= cl02+data.count("1 ")
#   cl03= cl03+data.count("2 ")
#   cl04= cl04+data.count("3 ")
#   f.close()
  
#   cls_count= [cl01,cl02,cl03,cl04]

# # function to add value labels
# def addlabels(x,y):
#     for i in range(len(x)):
#         plt.text(i, y[i], y[i], ha = 'center')
  
# if __name__ == '__main__':
    
#     # creating data on which bar chart will be plot
#     x = damageTypes
#     y = cls_count
      
#     # setting figure size by using figure() function 
#     plt.figure(figsize = (10, 5))
      
#     # making the bar chart on the data
#     plt.bar(x, y)
      
#     # calling the function to add value labels
#     addlabels(x, y)
      
#     # giving title to the plot
#     plt.title("Road Surface Damage Classes")
      
#     # giving X and Y labels
#     plt.xlabel("Object Class")
#     plt.ylabel("Class counts - Train")
      
#     # visualizing the plot
#     plt.show()

# # code for displaying multiple images in one figure

# #import libraries
# import cv2
# from matplotlib import pyplot as plt

# # create figure
# fig = plt.figure(figsize=(10, 7))

# # setting values to rows and column variables
# rows = 2
# columns = 3

# # reading images
# Image1 = cv2.imread('/content/yolov7/dataset/train/images/00001_Crack038.jpg')
# Image2 = cv2.imread('/content/yolov7/dataset/train/images/00001_Damage034.jpg')
# Image3 = cv2.imread('/content/yolov7/dataset/train/images/00001_Long023.jpg')
# Image4 = cv2.imread('/content/yolov7/dataset/train/images/00001_Long039.jpg')
# Image5 = cv2.imread('/content/yolov7/dataset/train/images/IRSDD_23042022_114.jpg')
# Image6 = cv2.imread('/content/yolov7/dataset/train/images/00001_Damage019.jpg')


# # Adds a subplot at the 1st position
# fig.add_subplot(rows, columns, 1)

# # showing image
# plt.imshow(Image1)
# plt.axis('off')
# plt.title("First")

# # Adds a subplot at the 2nd position
# fig.add_subplot(rows, columns, 2)

# # showing image
# plt.imshow(Image2)
# plt.axis('off')
# plt.title("Second")

# # Adds a subplot at the 3rd position
# fig.add_subplot(rows, columns, 3)

# # showing image
# plt.imshow(Image3)
# plt.axis('off')
# plt.title("Third")

# # Adds a subplot at the 4th position
# fig.add_subplot(rows, columns, 4)

# # showing image
# plt.imshow(Image4)
# plt.axis('off')
# plt.title("Fourth")
# fig.add_subplot(rows, columns, 5)
# # showing image
# plt.imshow(Image5)
# plt.axis('off')
# plt.title("Fifth")
# fig.add_subplot(rows, columns, 6)
# # showing image
# plt.imshow(Image6)
# plt.axis('off')
# plt.title("Sixth")

"""# Evaluation

We can evaluate the performance of our custom training using the provided evalution script.

Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154).
"""

# Commented out IPython magic to ensure Python compatibility.
# Run evaluation
# %cd /content/yolov7
!python detect.py --weights /content/yolov7/run/best.pt --conf 0.1 --source /content/RSDD2022/Video/testvideo_3.mp4

#display inference on ALL test images

import glob
from IPython.display import Image, display

i = 0
limit = 10000 # max images to print
for imageName in glob.glob('/content/yolov7/runs/detect/exp/*.jpg'): #assuming JPG
    if i < limit:
      display(Image(filename=imageName))
      print("\n")
    i = i + 1



"""# Reparameterize for Inference

https://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb

# OPTIONAL: Deployment

To deploy, you'll need to export your weights and save them to use later.
"""

# Commented out IPython magic to ensure Python compatibility.
''' 
Trained folder zip it and download
'''
from google.colab import files
# %cd /content/yolov7
#!zip -r /content/TNRSDD2023_train.zip /content/yolov7/runs/train/TNRSDD20234
!files.download('/content/TNRSDD2023_train.zip')

"""# OPTIONAL: Active Learning Example

Once our first training run is complete, we should use our model to help identify which images are most problematic in order to investigate, annotate, and improve our dataset (and, therefore, model).

To do that, we can execute code that automatically uploads images back to our hosted dataset if the image is a specific class or below a given confidence threshold.

"""

# # setup access to your workspace
# rf = Roboflow(api_key="YOUR_API_KEY")                               # used above to load data
# inference_project =  rf.workspace().project("YOUR_PROJECT_NAME")    # used above to load data
# model = inference_project.version(1).model

# upload_project = rf.workspace().project("YOUR_PROJECT_NAME")

# print("inference reference point: ", inference_project)
# print("upload destination: ", upload_project)

# # example upload: if prediction is below a given confidence threshold, upload it 

# confidence_interval = [10,70]                                   # [lower_bound_percent, upper_bound_percent]

# for prediction in predictions:                                  # predictions list to loop through
#   if(prediction['confidence'] * 100 >= confidence_interval[0] and 
#           prediction['confidence'] * 100 <= confidence_interval[1]):
        
#           # upload on success!
#           print(' >> image uploaded!')
#           upload_project.upload(image, num_retry_uploads=3)     # upload image in question

"""# Next steps

Congratulations, you've trained a custom YOLOv7 model! Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild.
"""